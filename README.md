# Exploration - Deep Learning

#  1ï¸âƒ£ Notebook 1 : modÃ¨le PyTorch sur un dataset de chiffres manuscrits

## Objectifs :
- **PrÃ©parer les donnÃ©es** : Charger et prÃ©traiter le dataset MNIST.
- **Construire le modÃ¨le** : DÃ©finir une architecture de rÃ©seau de neurones en utilisant PyTorch.
- **EntraÃ®ner le modÃ¨le** : Utiliser une boucle d'entraÃ®nement pour ajuster les poids du modÃ¨le.
- **Ã‰valuer le modÃ¨le** : Tester le modÃ¨le sur des donnÃ©es de test et Ã©valuer sa performance.
- **Visualiser les rÃ©sultats** : Afficher des exemples de prÃ©dictions du modÃ¨le.

### Contenu du Notebook :

1. **Importation des bibliothÃ¨ques** :
   - Importation de PyTorch et des modules nÃ©cessaires (`torch`, `torch.nn`, `torch.optim`, `torchvision`).

2. **PrÃ©paration des donnÃ©es** :
   - Chargement et transformation du dataset MNIST en utilisant `torchvision.datasets` et `torchvision.transforms`.
   - CrÃ©ation des DataLoader pour les ensembles d'entraÃ®nement et de test.

3. **Construction du modÃ¨le** :
   - DÃ©finition d'un rÃ©seau de neurones simple avec des couches entiÃ¨rement connectÃ©es en utilisant `torch.nn`.

4. **EntraÃ®nement du modÃ¨le** :
   - DÃ©finition de la fonction de perte (`CrossEntropyLoss`) et de l'optimiseur (`AdamW`).
   - ImplÃ©mentation de la boucle d'entraÃ®nement pour ajuster les poids du modÃ¨le.

5. **Ã‰valuation du modÃ¨le** :
   - ImplÃ©mentation de la boucle de test pour Ã©valuer la performance du modÃ¨le sur l'ensemble de test.

6. **Visualisation des rÃ©sultats** :
   - Affichage d'exemples de prÃ©dictions du modÃ¨le avec les labels rÃ©els et prÃ©dits en utilisant `matplotlib`.

# 2ï¸âƒ£ Notebook 2 : LSTM avec Tokenisation BPE

## ğŸ“ Objectif :
CrÃ©er un modÃ¨le **LSTM** (Long Short-Term Memory) qui apprend Ã  gÃ©nÃ©rer du texte en sâ€™appuyant sur une **tokenisation avancÃ©e** (BPE - Byte Pair Encoding). Cela permet de mieux gÃ©rer les mots inconnus et de rÃ©duire la taille du vocabulaire.

## ğŸš€ RÃ©sumÃ© :
- **PrÃ©traitement des donnÃ©es** : transformation du texte en une suite de nombres avec **SentencePiece**.
- **Construction du modÃ¨le LSTM** :
  - Une premiÃ¨re couche qui transforme chaque nombre en une reprÃ©sentation plus riche (**embedding**).
  - Un rÃ©seau LSTM qui apprend Ã  anticiper la suite des phrases.
  - Une derniÃ¨re couche qui prÃ©dit le mot suivant en lui attribuant une probabilitÃ©.
- **EntraÃ®nement** : le modÃ¨le sâ€™ajuste en comparant ses erreurs et en les corrigeant Ã  chaque passage.
- **GÃ©nÃ©ration de texte** :
  - On donne un dÃ©but de phrase au modÃ¨le.
  - Il devine progressivement les mots suivants.

## âš™ï¸ Ã‰tapes dâ€™exÃ©cution :
1. **Lancer le notebook pour charger et prÃ©parer les donnÃ©es.**  
2. **Lancer l'entraÃ®nement du modÃ¨le LSTM.**  
3. **Tester la gÃ©nÃ©ration de texte avec `generate_text_bpe()`.**  
4. **Observer comment le modÃ¨le produit des phrases cohÃ©rentes au fil des entraÃ®nements.**

---

# 3ï¸âƒ£ Notebook 3 : Transformer

## ğŸ“ Objectif :
CrÃ©er un **modÃ¨le Transformer** qui gÃ©nÃ¨re du texte en comprenant **tout le contexte en mÃªme temps**, contrairement Ã  un LSTM qui lit le texte **mot aprÃ¨s mot**.

## ğŸš€ RÃ©sumÃ© :
- **ComprÃ©hension du contexte global** : Chaque mot de la phrase "regarde" tous les autres pour mieux comprendre sa place et son sens.
- **Construction du Transformer** :
  - Une premiÃ¨re couche qui transforme chaque mot en une reprÃ©sentation comprÃ©hensible (**embedding**).
  - Un mÃ©canisme dâ€™**attention** qui fait le tri dans les mots importants pour construire la phrase.
  - Un **dÃ©codeur** qui gÃ©nÃ¨re le texte, mot aprÃ¨s mot, en prenant en compte tout ce qui a Ã©tÃ© Ã©crit avant.
- **EntraÃ®nement** :
  - Le modÃ¨le apprend en ajustant ses prÃ©dictions et en minimisant ses erreurs.
- **GÃ©nÃ©ration de texte** :
  - Ã€ partir dâ€™un mot donnÃ©, il construit une phrase en choisissant Ã  chaque Ã©tape le mot le plus logique.

## âš™ï¸ Ã‰tapes dâ€™exÃ©cution :
1. **Lancer l'entraÃ®nement du Transformer sur les donnÃ©es tokenisÃ©es.**  
2. **Tester la gÃ©nÃ©ration avec `generate_text_transformer()`.**  
3. **Comparer la qualitÃ© des phrases gÃ©nÃ©rÃ©es avec celles du modÃ¨le LSTM.**

---

## ğŸ” DiffÃ©rence clÃ© entre LSTM et Transformer :
âœ… **LSTM** â†’ Lit les mots **un par un** et mÃ©morise ceux dâ€™avant pour anticiper la suite.  
âœ… **Transformer** â†’ Comprend **toute la phrase dâ€™un coup** et choisit le mot suivant en analysant lâ€™ensemble du contexte.

Globalement le **Transformer** est plus performant pour gÃ©nÃ©rer des phrases cohÃ©rentes, mais il est plus lent Ã  apprendre.


# 4ï¸âƒ£  Notebook 4 : RAG - Chatbot Intelligent avec Recherche Documentaire et SynthÃ¨se Vocale en local 

Ce **pipeline RAG** (**Retrieval-Augmented Generation**) permet d'**amÃ©liorer la prÃ©cision des rÃ©ponses d'un modÃ¨le de langage** en le forÃ§ant Ã  **ne pas se baser uniquement sur sa donnÃ©e d'entraÃ®nement**, mais Ã  **synthÃ©tiser des informations extraites de documents**. GrÃ¢ce Ã  ce processus, les rÃ©ponses sont **plus prÃ©cises, actualisÃ©es et adaptÃ©es aux documents fournis dans le fichier  ```documents.zip``` et Ã  mettre dans un dossier ```/data```** vous aurez donc deux fichiers `connaissances.txt` et  `document.pdf`.

## ğŸ› ï¸ FonctionnalitÃ©s
- ğŸ” **Recherche augmentÃ©e** : interroge des documents locaux (`connaissances.txt`, `document.pdf`) avant de gÃ©nÃ©rer une rÃ©ponse.  
- ğŸ’¡ **ModÃ¨le de gÃ©nÃ©ration Mistral 7B** (llama-cpp-python) exÃ©cutÃ© **en local**.  
- ğŸ“š **Stockage et recherche rapide dâ€™informations avec ChromaDB**  pour rÃ©cupÃ©rer les informations les plus pertinentes avant de gÃ©nÃ©rer une rÃ©ponse.
  - 1ï¸âƒ£ Premier lancement â†’ Lâ€™index est crÃ©Ã© et sauvegardÃ© dans ```models/chromadb```
  - 2ï¸âƒ£ ExÃ©cutions suivantes â†’ Lâ€™index est directement rechargÃ© depuis ```models/chromadb```, sans tout recalculer.
  â†’ Lâ€™index c'est simplement une base de donnÃ©es optimisÃ©e qui stocke les versions vectorisÃ©es de `connaissances.txt` et de `document.pdf` , ce qui permet au modÃ¨le de rechercher rapidement des informations pertinentes avant de rÃ©pondre et pas recalculer Ã  chaque fois.

- ğŸŒ **API Flask** (`/chat`) qui gÃ¨re la communication entre le modÃ¨le et l'interface web.  
- ğŸ¤ **SynthÃ¨se vocale Bark** : **une voix pour la question, une autre pour la rÃ©ponse**.  
- ğŸ–¥ï¸ **Interface web (`index.html`) pour interagir avec le chatbot**.

---

## âš¡ Comment lâ€™utiliser ?
1. **Lancer le Jupyter Notebook**  
2. **L'interface `index.html` sera gÃ©nÃ©rÃ©e automatiquement**  
3. **Ouvrir `index.html` dans un navigateur**  
![page web](img/index_example_web_page.png)
4. **Poser une question (ex. : "Comment faire une tarte aux pommes ?")**  
5. **Le chatbot dans un premier temps rÃ©pÃ¨te la question aprÃ¨s l'avoir intÃ©grÃ©e puis la rÃ©pÃ¨te Ã  voix haute, puis l'analyse des documents se lance, gÃ©nÃ¨re une rÃ©ponse et la lit Ã  voix haute Ã©galement**  
![page web aprÃ¨s rÃ©ponse](img/index_example_web_page_answered.png)
---



## âœ… Questions de test pour vÃ©rifier le RAG
- ```Quelles sont les diffÃ©rentes variantes de la tarte aux pommes ?```  
- ```Comment faire une tarte aux pommes ?```  
- ```Quel est le secret dâ€™une bonne tarte aux pommes ?``` 

---

## ğŸ’¡ AmÃ©liorations possibles
- ğŸ”Š **Utiliser une voix encore plus naturelle** (XTTS, Coqui-TTS...)  
- â˜ï¸ **DÃ©ployer lâ€™API Flask en ligne** pour lâ€™utiliser Ã  distance  


# Exploration - Deep Learning

#  1ï¸âƒ£ Notebook 1 : 
modÃ¨le PyTorch sur un dataset de chiffres manuscrits

# 2ï¸âƒ£ Notebook 2 : LSTM avec Tokenisation BPE
CrÃ©er un modÃ¨le **LSTM** capable de gÃ©nÃ©rer du texte
-> **Objectif** : CrÃ©er un modÃ¨le **LSTM** capable de gÃ©nÃ©rer du texte 

# 3ï¸âƒ£ Notebook 3 : Transformers
CrÃ©er un modÃ¨le **Transformer** capable de gÃ©nÃ©rer du texte
-> **Objectif** : CrÃ©er un **Transformer** , avec un **encodeur (Ã©metteur) et un dÃ©codeur (rÃ©cepteur)**, pour la gÃ©nÃ©ration de texte.


# 4ï¸âƒ£  Notebook 4 : RAG - Chatbot Intelligent avec Recherche Documentaire et SynthÃ¨se Vocale

Ce **pipeline RAG** (**Retrieval-Augmented Generation**) permet d'**amÃ©liorer la prÃ©cision des rÃ©ponses d'un modÃ¨le de langage** en le forÃ§ant Ã  **ne pas se baser uniquement sur sa donnÃ©e d'entraÃ®nement**, mais Ã  **synthÃ©tiser des informations extraites de documents**. GrÃ¢ce Ã  ce processus, les rÃ©ponses sont **plus prÃ©cises, actualisÃ©es et adaptÃ©es aux documents fournis dans le fichier  ```documents.zip``` et Ã  mettre dans un dossier ```/data```** vous aurez donc deux fichiers `connaissances.txt` et  `document.pdf`.

## ğŸ› ï¸ FonctionnalitÃ©s
- ğŸ” **Recherche augmentÃ©e** : interroge des documents locaux (`connaissances.txt`, `document.pdf`) avant de gÃ©nÃ©rer une rÃ©ponse.  
- ğŸ’¡ **ModÃ¨le de gÃ©nÃ©ration Mistral 7B** (llama-cpp-python) exÃ©cutÃ© **en local**.  
- ğŸ“š **Stockage et recherche rapide dâ€™informations avec ChromaDB**  pour rÃ©cupÃ©rer les informations les plus pertinentes avant de gÃ©nÃ©rer une rÃ©ponse.
  - 1ï¸âƒ£ Premier lancement â†’ Lâ€™index est crÃ©Ã© et sauvegardÃ© dans ```models/chromadb```
  - 2ï¸âƒ£ ExÃ©cutions suivantes â†’ Lâ€™index est directement rechargÃ© depuis ```models/chromadb```, sans tout recalculer.
  â†’ Lâ€™index c'est simplement une base de donnÃ©es optimisÃ©e qui stocke les versions vectorisÃ©es de `connaissances.txt` et de `document.pdf` , ce qui permet au modÃ¨le de rechercher rapidement des informations pertinentes avant de rÃ©pondre et pas recalculer Ã  chaque fois.

- ğŸŒ **API Flask** (`/chat`) qui gÃ¨re la communication entre le modÃ¨le et l'interface web.  
- ğŸ¤ **SynthÃ¨se vocale Bark** : **une voix pour la question, une autre pour la rÃ©ponse**.  
- ğŸ–¥ï¸ **Interface web (`index.html`) pour interagir avec le chatbot**.

---

## âš¡ Comment lâ€™utiliser ?
1. **Lancer le Jupyter Notebook**  
2. **L'interface `index.html` sera gÃ©nÃ©rÃ©e automatiquement**  
3. **Ouvrir `index.html` dans un navigateur**  
![page web](img/index_example_web_page.png)
4. **Poser une question (ex. : "Comment faire une tarte aux pommes ?")**  
5. **Le chatbot dans un premier temps rÃ©pÃ¨te la question aprÃ¨s l'avoir intÃ©grÃ©e puis la rÃ©pÃ¨te Ã  voix haute, puis l'analyse des documents se lance, gÃ©nÃ¨re une rÃ©ponse et la lit Ã  voix haute Ã©galement**  
![page web aprÃ¨s rÃ©ponse](img/index_example_web_page_answered.png)
---



## âœ… Questions de test pour vÃ©rifier le RAG
- ```Quelles sont les diffÃ©rentes variantes de la tarte aux pommes ?```  
- ```Comment faire une tarte aux pommes ?```  
- ```Quel est le secret dâ€™une bonne tarte aux pommes ?``` 

---

## ğŸ’¡ AmÃ©liorations possibles
- ğŸ”Š **Utiliser une voix encore plus naturelle** (XTTS, Coqui-TTS...)  
- â˜ï¸ **DÃ©ployer lâ€™API Flask en ligne** pour lâ€™utiliser Ã  distance  

